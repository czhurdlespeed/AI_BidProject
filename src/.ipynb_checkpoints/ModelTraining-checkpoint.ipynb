{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70b7defc-64ab-461e-ad66-240ca8d366a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "25fb740a-db58-422c-86ea-5c83a85e4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../Data/X_train.npy\", allow_pickle=True).T\n",
    "X_test = np.load(\"../Data/X_test.npy\", allow_pickle=True).T\n",
    "y_train = np.load(\"../Data/y_train.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"../Data/y_test.npy\", allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ceca1eeb-f09b-42a4-ae60-4e76ae7ae21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type, input_dim=None, **kwargs):\n",
    "    if model_type == 'neural_network':\n",
    "        inputs = Input(shape=(input_dim, ))\n",
    "        x = Dense(64, input_dim=input_dim, activation='relu')(inputs)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(**kwargs)\n",
    "    elif model_type == 'svm':\n",
    "        model = SVC(probability=True, **kwargs)\n",
    "    elif model_type == 'xgboost':\n",
    "        model = xgb.XGBClassifier(eval_metric='logloss', **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "36699b28-2e82-483d-9248-78fcecec3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_type, epochs=100, batch_size=32, validation_split=0.1, **kwargs):\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = create_model(model_type, input_dim, **kwargs)\n",
    "    \n",
    "    if model_type in ['neural_network']:\n",
    "        def lr_schedule(epoch):\n",
    "            return 0.001 * (0.1 ** int(epoch / 10))\n",
    "        #lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            validation_split=validation_split,\n",
    "            #callbacks=[lr_scheduler],\n",
    "            verbose=1  # Set to 0 for no output, 1 for progress bar, 2 for one line per epoch\n",
    "        )\n",
    "    else:\n",
    "        # For non-TensorFlow models\n",
    "        model.fit(X_train, y_train)\n",
    "        history = None\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6d09ea30-941a-4018-9d2a-15e301a08bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_feature_selection(X_train, y_train, X_test, model_type, epochs=100, batch_size=32, validation_split=0.1, **kwargs):\n",
    "    selector = VarianceThreshold()\n",
    "    X_train = selector.fit_transform(X_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    # Select top k features\n",
    "    k = min(250, X_train.shape[1])  # Ensure k is not larger than the number of features\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    input_dim = X_train_selected.shape[1]\n",
    "    model = create_model(model_type, input_dim=input_dim, **kwargs)\n",
    "    if model_type in ['neural_network']:\n",
    "        def lr_schedule(epoch):\n",
    "            return 0.001 * (0.1 ** int(epoch / 10))\n",
    "        #lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        history = model.fit(\n",
    "            X_train_selected, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight_dict,\n",
    "            validation_split=validation_split,\n",
    "            #callbacks=[lr_scheduler],\n",
    "            verbose=1  # Set to 0 for no output, 1 for progress bar, 2 for one line per epoch\n",
    "        )\n",
    "    return model, history, X_test_selected\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d9041974-050a-4f39-85f3-7ff837885f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, metrics=None):\n",
    "    \"\"\"\n",
    "    Plot training history of a TensorFlow model.\n",
    "    \n",
    "    :param history: History object returned by model.fit()\n",
    "    :param metrics: List of metrics to plot (optional). If None, plots all available metrics.\n",
    "    \"\"\"\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    epochs = range(1, len(next(iter(history.values()))) + 1)\n",
    "\n",
    "    if metrics is None:\n",
    "        metrics = [m for m in history.keys() if not m.startswith('val_')]\n",
    "\n",
    "    plt.figure(figsize=(12, 4 * len(metrics)))\n",
    "    \n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(len(metrics), 1, i)\n",
    "        \n",
    "        plt.plot(epochs, history[metric], 'bo-', label=f'Training {metric}')\n",
    "        if f'val_{metric}' in history:\n",
    "            plt.plot(epochs, history[f'val_{metric}'], 'ro-', label=f'Validation {metric}')\n",
    "        \n",
    "        plt.title(f'{metric.capitalize()} vs. Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        \n",
    "        if metric == 'loss':\n",
    "            plt.yscale('log')  # Use log scale for loss\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b361bb5c-6e76-4971-8912-870cef838206",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 12) (937199572.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[139], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    if model_type in [neural_network']:\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 12)\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, X_test, y_test, model_type):\n",
    "    \"\"\"\n",
    "    Test the model on the test set and return various performance metrics.\n",
    "    \n",
    "    :param model: Trained model\n",
    "    :param X_test: Test features\n",
    "    :param y_test: True labels for test set\n",
    "    :param model_type: Type of the model ('neural_network', 'random_forest', 'svm', 'xgboost')\n",
    "    :return: Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    if model_type in ['neural_network']:\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # For TensorFlow models, also get the loss\n",
    "    if model_type in ['neural_network']:\n",
    "        loss = model.evaluate(X_test, y_test)[0]\n",
    "    else:\n",
    "        loss = None\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'loss': loss\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a15fc-cf8a-4f56-8dfd-cb3e0baef6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, history = train_model(X_train, y_train, model_type='neural_network', epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee4343-8698-489c-ab18-e33b153415df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, metrics=['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eb017-efbc-47fb-9c17-af91546ea381",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_model(model, X_test, y_test, model_type='neural_network')\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e22a3-be6e-492b-b05c-3d8800ec41b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, history, X_test_feature_selection = train_model_feature_selection(X_train, y_train, X_test, model_type='neural_network', epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab70fb8-c60e-49a0-8e7e-a802e44ebf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, metrics=['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a939b9a-0a89-495a-b921-ba99ff602751",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_model(model, X_test_feature_selection, y_test, model_type='neural_network')\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e172c2-572c-40e3-811a-19ba419f115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(X_train, y_train, model_type='xgboost', epochs=100)\n",
    "test_results = test_model(model, X_test, y_test, model_type='xgboost')\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da63d3-876c-4f73-a6e8-ed816fe4e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(X_train, y_train, model_type='random_forest', epochs=100)\n",
    "test_results = test_model(model, X_test, y_test, model_type='random_forest')\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf64092-af1c-4c0a-8425-11e103ff4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(X_train, y_train, model_type='svm', epochs=100)\n",
    "test_results = test_model(model, X_test, y_test, model_type='svm')\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b99a3f-4c03-45a7-88a1-80abfa748bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
